{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64dca70d-5901-4559-8a2c-74555376093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported the EMNIST libraries we need!\n",
      "Extracted our samples and divided our training and testing data sets\n",
      "Created our first MLP network\n",
      "Iteration 1, loss = 1.06351395\n",
      "Iteration 2, loss = 0.64844650\n",
      "Iteration 3, loss = 0.56103245\n",
      "Iteration 4, loss = 0.51987725\n",
      "Iteration 5, loss = 0.49182099\n",
      "Iteration 6, loss = 0.47301057\n",
      "Iteration 7, loss = 0.45839220\n",
      "Iteration 8, loss = 0.44603836\n",
      "Iteration 9, loss = 0.43479721\n",
      "Iteration 10, loss = 0.42809575\n",
      "Iteration 11, loss = 0.41639233\n",
      "Iteration 12, loss = 0.40782908\n",
      "Iteration 13, loss = 0.40548360\n",
      "Iteration 14, loss = 0.39965983\n",
      "Iteration 15, loss = 0.39296832\n",
      "Iteration 16, loss = 0.38883219\n",
      "Iteration 17, loss = 0.38393955\n",
      "Iteration 18, loss = 0.37948343\n",
      "Iteration 19, loss = 0.37307616\n",
      "Iteration 20, loss = 0.37166732\n",
      "Training set score: 0.886500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mothafucka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.840800\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 84 times that the letter i was predicted to be the letter l.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.15599672\n",
      "Iteration 2, loss = 0.54834774\n",
      "Iteration 3, loss = 0.44784035\n",
      "Iteration 4, loss = 0.39865207\n",
      "Iteration 5, loss = 0.36308811\n",
      "Iteration 6, loss = 0.33567397\n",
      "Iteration 7, loss = 0.31904877\n",
      "Iteration 8, loss = 0.29485588\n",
      "Iteration 9, loss = 0.27846574\n",
      "Iteration 10, loss = 0.26938228\n",
      "Iteration 11, loss = 0.25802023\n",
      "Iteration 12, loss = 0.25723763\n",
      "Iteration 13, loss = 0.24092200\n",
      "Iteration 14, loss = 0.23226412\n",
      "Iteration 15, loss = 0.23512006\n",
      "Iteration 16, loss = 0.22575190\n",
      "Iteration 17, loss = 0.22427105\n",
      "Iteration 18, loss = 0.22087140\n",
      "Iteration 19, loss = 0.21420822\n",
      "Iteration 20, loss = 0.20687608\n",
      "Iteration 21, loss = 0.20286756\n",
      "Iteration 22, loss = 0.20410037\n",
      "Iteration 23, loss = 0.19924623\n",
      "Iteration 24, loss = 0.19453563\n",
      "Iteration 25, loss = 0.20100520\n",
      "Iteration 26, loss = 0.19723902\n",
      "Iteration 27, loss = 0.19461739\n",
      "Iteration 28, loss = 0.19810787\n",
      "Iteration 29, loss = 0.19411719\n",
      "Iteration 30, loss = 0.19403925\n",
      "Iteration 31, loss = 0.18427764\n",
      "Iteration 32, loss = 0.17936913\n",
      "Iteration 33, loss = 0.18794325\n",
      "Iteration 34, loss = 0.18921546\n",
      "Iteration 35, loss = 0.17923619\n",
      "Iteration 36, loss = 0.18739129\n",
      "Iteration 37, loss = 0.17783602\n",
      "Iteration 38, loss = 0.18085960\n",
      "Iteration 39, loss = 0.18319824\n",
      "Iteration 40, loss = 0.17591093\n",
      "Iteration 41, loss = 0.18045202\n",
      "Iteration 42, loss = 0.17807562\n",
      "Iteration 43, loss = 0.17308203\n",
      "Iteration 44, loss = 0.17779780\n",
      "Iteration 45, loss = 0.16804696\n",
      "Iteration 46, loss = 0.17823998\n",
      "Iteration 47, loss = 0.17307166\n",
      "Iteration 48, loss = 0.18442473\n",
      "Iteration 49, loss = 0.18199847\n",
      "Iteration 50, loss = 0.17013298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mothafucka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.950067\n",
      "Test set score: 0.889100\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c8ac6d80b75a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;31m# Puts all the data in the \"files\" variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"letters_mod\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from emnist import extract_training_samples\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "import numpy\n",
    "import cv2\n",
    "\n",
    "print(\"Imported the EMNIST libraries we need!\")\n",
    "\n",
    "# X will be our images and y will be the labels\n",
    "X, y = extract_training_samples('letters')\n",
    "\n",
    "# Make sure that every pixel in all of the images is a value between 0 and 1\n",
    "X = X / 255.\n",
    "\n",
    "# Use the first 60000 instances as training and the next 10000 as testing\n",
    "X_train, X_test = X[:60000], X[60000:70000]\n",
    "y_train, y_test = y[:60000], y[60000:70000]\n",
    "\n",
    "# record the number of samples in each dataset and the number of pixels in each image\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "print(\"Extracted our samples and divided our training and testing data sets\")\n",
    "\n",
    "# This creates our first MLP with 1 hidden layer with 50 neurons and sets it to run through the data 20 times\n",
    "mlp1 = MLPClassifier(hidden_layer_sizes=(50,), max_iter=20, alpha=1e-4,\n",
    "                     solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                     learning_rate_init=.1)\n",
    "\n",
    "print(\"Created our first MLP network\")\n",
    "\n",
    "mlp1.fit(X_train, y_train)\n",
    "print(\"Training set score: %f\" % mlp1.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp1.score(X_test, y_test))\n",
    "\n",
    "# First let's initialize a list with all the predicted values from the training set\n",
    "y_pred = mlp1.predict(X_test)\n",
    "\n",
    "# Now let's visualize the errors between the predictions and the actual labels using a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.matshow(cm)\n",
    "plt.show()\n",
    "\n",
    "# You can change this to any letters that you think the neural network may have confused...\n",
    "predicted_letter = 'l'\n",
    "actual_letter = 'i'\n",
    "\n",
    "# This code counts all mistakes for the letters above\n",
    "mistake_list = []\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == (ord(actual_letter) - 96) and y_pred[i] == (ord(predicted_letter) - 96):\n",
    "        mistake_list.append(i)\n",
    "print(\"There were \" + str(\n",
    "    len(mistake_list)) + \" times that the letter \" + actual_letter + \" was predicted to be the letter \" + predicted_letter + \".\")\n",
    "\n",
    "# Once we know how many mistakes were made, we can change this to see an image of a particular one\n",
    "mistake_to_show = 4  # <<< e.g., change this to 3 if you want to see the 4th mistake\n",
    "\n",
    "# This code checks that the number mistake you asked for can be shown and if so, displays an image of it\n",
    "if len(mistake_list) > mistake_to_show:\n",
    "    img = X_test[mistake_list[mistake_to_show]]\n",
    "    plt.imshow(img.reshape((28, 28)))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Couldn't show mistake number \" + str(mistake_to_show + 1) + \" because there were only \" + str(\n",
    "        len(mistake_list)) + \" mistakes to show!\")\n",
    "\n",
    "# Change some of the values in the below statement and re-run to see how they\n",
    "# affect performance!\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100,), max_iter=50, alpha=1e-4,\n",
    "                     solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                     learning_rate_init=.1)\n",
    "mlp2.fit(X_train, y_train)\n",
    "print(\"Training set score: %f\" % mlp2.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp2.score(X_test, y_test))\n",
    "\n",
    "# Puts all the data in the \"files\" variable\n",
    "path, dirs, files = next(os.walk(\"letters_mod\"))\n",
    "files.sort()\n",
    "\n",
    "# This code processes all the scanned images and adds them to the handwritten_story\n",
    "handwritten_story = []\n",
    "for i in range(len(files)):\n",
    "    img = cv2.imread(\"letters_mod\" + files[i], cv2.IMREAD_GRAYSCALE)\n",
    "    handwritten_story.append(img)\n",
    "\n",
    "print(\"Imported the scanned images.\")\n",
    "\n",
    "plt.imshow(handwritten_story[4])  # <--- Change this index to see different letters\n",
    "plt.show()\n",
    "\n",
    "typed_story = \"\"\n",
    "for letter in handwritten_story:\n",
    "    letter = cv2.resize(letter, (28, 28), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # this bit of code checks to see if the image is just a blank space by looking at the color of all the pixels summed\n",
    "    total_pixel_value = 0\n",
    "    for j in range(28):\n",
    "        for k in range(28):\n",
    "            total_pixel_value += letter[j, k]\n",
    "    if total_pixel_value < 20:\n",
    "        typed_story = typed_story + \" \"\n",
    "    else:  # if it NOT a blank, it actually runs the prediction algorithm on it\n",
    "        single_item_array = (numpy.array(letter)).reshape(1, 784)\n",
    "        prediction = mlp2.predict(single_item_array)\n",
    "        typed_story = typed_story + str(chr(prediction[0] + 96))\n",
    "\n",
    "print(\"Conversion to typed story complete!\")\n",
    "print(typed_story)\n",
    "\n",
    "# These steps process the scanned images to be in the same format and have the same properties as the EMNIST images\n",
    "# They are described by the EMNIST authors in detail here: https://arxiv.org/abs/1702.05373v1\n",
    "processed_story = []\n",
    "\n",
    "for img in handwritten_story:\n",
    "    # step 1: Apply Gaussian blur filter\n",
    "    img = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "\n",
    "    # steps 2 and 3: Extract the Region of Interest in the image and center in square\n",
    "    points = cv2.findNonZero(img)\n",
    "    x, y, w, h = cv2.boundingRect(points)\n",
    "    if w > 0 and h > 0:\n",
    "        if w > h:\n",
    "            y = y - (w - h) // 2\n",
    "            img = img[y:y + w, x:x + w]\n",
    "        else:\n",
    "            x = x - (h - w) // 2\n",
    "            img = img[y:y + h, x:x + h]\n",
    "\n",
    "    # step 4: Resize and resample to be 28 x 28 pixels\n",
    "    img = cv2.resize(img, (28, 28), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # step 5: Normalize pixels and reshape before adding to the new story array\n",
    "    img = img / 255\n",
    "    img = img.reshape((28, 28))\n",
    "    processed_story.append(img)\n",
    "\n",
    "print(\"Processed the scanned images.\")\n",
    "\n",
    "plt.imshow(processed_story[4])  # <<< change this index if you want to see a different letter from the story\n",
    "plt.show()\n",
    "\n",
    "typed_story = \"\"\n",
    "for letter in processed_story:\n",
    "    # this bit of code checks to see if the image is just a blank space by looking at the color of all the pixels summed\n",
    "    total_pixel_value = 0\n",
    "    for j in range(28):\n",
    "        for k in range(28):\n",
    "            total_pixel_value += letter[j, k]\n",
    "    if total_pixel_value < 20:\n",
    "        typed_story = typed_story + \" \"\n",
    "    else:  # if it NOT a blank, it actually runs the prediction algorithm on it\n",
    "        single_item_array = (numpy.array(letter)).reshape(1, 784)\n",
    "        prediction = mlp2.predict(single_item_array)\n",
    "        typed_story = typed_story + str(chr(prediction[0] + 96))\n",
    "\n",
    "print(\"Conversion to typed story complete!\")\n",
    "print(typed_story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5bb8797-77f8-47a0-a26e-63c8c2ff72e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported the EMNIST libraries we need!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sorki/python-mnist\n",
    "!./python-mnist/bin/mnist_get_data.sh\n",
    "!pip3 install emnist\n",
    "from emnist import extract_training_samples\n",
    "\n",
    "print(\"Imported the EMNIST libraries we need!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f19bbec8-3026-4721-8627-1f24e8493592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'lab1-neural-networks'...\n",
      "fatal: not a git repository (or any of the parent directories): .git\n",
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "The system cannot find the path specified.\n",
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/crash-course-ai/lab1-neural-networks.git\n",
    "!git pull\n",
    "!ls lab1-neural-networks/letters_mod\n",
    "!cd /content/lab1-neural-networks/letters_mod\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df68a71d-43b9-484a-a9cf-77642a7d7ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
